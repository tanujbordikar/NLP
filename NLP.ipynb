{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "676d6cd0-3203-4a6a-b639-f9c02e33e56d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting nlp\n",
      "  Using cached nlp-0.4.0-py3-none-any.whl (1.7 MB)\n",
      "Collecting pyarrow>=0.16.0\n",
      "  Downloading pyarrow-9.0.0-cp39-cp39-win_amd64.whl (19.6 MB)\n",
      "Collecting dill\n",
      "  Downloading dill-0.3.5.1-py2.py3-none-any.whl (95 kB)\n",
      "Requirement already satisfied: numpy in c:\\users\\tanuj bordikar\\anaconda3\\lib\\site-packages (from nlp) (1.21.5)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\tanuj bordikar\\anaconda3\\lib\\site-packages (from nlp) (4.64.0)\n",
      "Collecting xxhash\n",
      "  Downloading xxhash-3.0.0-cp39-cp39-win_amd64.whl (29 kB)\n",
      "Requirement already satisfied: filelock in c:\\users\\tanuj bordikar\\anaconda3\\lib\\site-packages (from nlp) (3.6.0)\n",
      "Requirement already satisfied: pandas in c:\\users\\tanuj bordikar\\anaconda3\\lib\\site-packages (from nlp) (1.4.2)\n",
      "Requirement already satisfied: requests>=2.19.0 in c:\\users\\tanuj bordikar\\anaconda3\\lib\\site-packages (from nlp) (2.27.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\tanuj bordikar\\anaconda3\\lib\\site-packages (from requests>=2.19.0->nlp) (2021.10.8)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\tanuj bordikar\\anaconda3\\lib\\site-packages (from requests>=2.19.0->nlp) (1.26.9)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\tanuj bordikar\\anaconda3\\lib\\site-packages (from requests>=2.19.0->nlp) (3.3)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\tanuj bordikar\\anaconda3\\lib\\site-packages (from requests>=2.19.0->nlp) (2.0.4)\n",
      "Requirement already satisfied: colorama in c:\\users\\tanuj bordikar\\anaconda3\\lib\\site-packages (from tqdm>=4.27->nlp) (0.4.4)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\tanuj bordikar\\anaconda3\\lib\\site-packages (from pandas->nlp) (2021.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\users\\tanuj bordikar\\anaconda3\\lib\\site-packages (from pandas->nlp) (2.8.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\tanuj bordikar\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.1->pandas->nlp) (1.16.0)\n",
      "Installing collected packages: xxhash, pyarrow, dill, nlp\n",
      "Successfully installed dill-0.3.5.1 nlp-0.4.0 pyarrow-9.0.0 xxhash-3.0.0\n",
      "Collecting nlp\n",
      "  Downloading nlp-0.4.0-py3-none-any.whl (1.7 MB)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\tanuj bordikar\\anaconda3\\lib\\site-packages (from nlp) (4.64.0)\n",
      "Collecting pyarrow>=0.16.0\n",
      "  Downloading pyarrow-9.0.0-cp39-cp39-win_amd64.whl (19.6 MB)\n",
      "Requirement already satisfied: pandas in c:\\users\\tanuj bordikar\\anaconda3\\lib\\site-packages (from nlp) (1.4.2)\n",
      "Collecting xxhash\n",
      "  Using cached xxhash-3.0.0-cp39-cp39-win_amd64.whl (29 kB)\n",
      "Requirement already satisfied: requests>=2.19.0 in c:\\users\\tanuj bordikar\\anaconda3\\lib\\site-packages (from nlp) (2.27.1)\n",
      "Collecting dill\n",
      "  Using cached dill-0.3.5.1-py2.py3-none-any.whl (95 kB)\n",
      "Requirement already satisfied: filelock in c:\\users\\tanuj bordikar\\anaconda3\\lib\\site-packages (from nlp) (3.6.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\tanuj bordikar\\anaconda3\\lib\\site-packages (from nlp) (1.21.5)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\tanuj bordikar\\anaconda3\\lib\\site-packages (from requests>=2.19.0->nlp) (1.26.9)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\tanuj bordikar\\anaconda3\\lib\\site-packages (from requests>=2.19.0->nlp) (3.3)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\tanuj bordikar\\anaconda3\\lib\\site-packages (from requests>=2.19.0->nlp) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\tanuj bordikar\\anaconda3\\lib\\site-packages (from requests>=2.19.0->nlp) (2021.10.8)\n",
      "Requirement already satisfied: colorama in c:\\users\\tanuj bordikar\\anaconda3\\lib\\site-packages (from tqdm>=4.27->nlp) (0.4.4)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\tanuj bordikar\\anaconda3\\lib\\site-packages (from pandas->nlp) (2021.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\users\\tanuj bordikar\\anaconda3\\lib\\site-packages (from pandas->nlp) (2.8.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\tanuj bordikar\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.1->pandas->nlp) (1.16.0)\n",
      "Installing collected packages: xxhash, pyarrow, dill, nlp\n",
      "Successfully installed dill-0.3.5.1 nlp-0.4.0 pyarrow-9.0.0 xxhash-3.0.0\n"
     ]
    }
   ],
   "source": [
    "!pip install nlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9d83ff6a-b0c0-4df5-bab6-f2e1a4a949a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import nlp\n",
    "import random\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "cf430ce5-585b-4196-be4b-5e89f07404e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default\n"
     ]
    }
   ],
   "source": [
    "dataset = nlp.load_dataset('emotion')\n",
    "train = dataset['train']\n",
    "val = dataset['validation']\n",
    "test = dataset['test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "585be66c-94ab-49a2-a32b-291f5fd22524",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tweet(data):\n",
    "    tweets = [x['text'] for x in data]\n",
    "    labels = [x['label'] for x in data]\n",
    "    return tweets, labels\n",
    "tweets, labels = get_tweet(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "6933fd58-d838-4927-8db9-4585e92f73e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('i didnt feel humiliated', 'sadness')"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets[0], labels[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "1a97aaff-a8d8-4f44-8fc4-b6dca5867f08",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(num_words=10000, oov_token='<UNK>')\n",
    "tokenizer.fit_on_texts(tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "87b57730-84fe-42f4-90e8-46d20cd1dc66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[2, 139, 3, 679]]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.texts_to_sequences([tweets[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "aae2a9aa-d3fa-413c-9edd-e515b6743516",
   "metadata": {},
   "outputs": [],
   "source": [
    "maxlen=50\n",
    "def get_sequences(tokenizer, tweets):\n",
    "    sequences = tokenizer.texts_to_sequences(tweets)\n",
    "    padded = pad_sequences(sequences, truncating = 'post', padding='post', maxlen=maxlen)\n",
    "    return padded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "79391836-c8eb-4ffd-9297-10e774b65987",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  2, 139,   3, 679,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "padded_train_seq = get_sequences(tokenizer, tweets)\n",
    "padded_train_seq[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "454a3244-ecd8-436b-be81-f2b30c3adefd",
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = set(labels)\n",
    "class_to_index = dict((c,i) for i, c in enumerate(classes))\n",
    "index_to_class = dict((v,k) for k, v in class_to_index.items())\n",
    "names_to_ids = lambda labels: np.array([class_to_index.get(x) for x in labels])\n",
    "train_labels = names_to_ids(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "65741381-1df5-4078-b129-193652e0bba7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'surprise', 'fear', 'love', 'sadness', 'anger', 'joy'}\n"
     ]
    }
   ],
   "source": [
    "print(classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "29b1ca39-fced-47b9-b69f-31e05d3d3dfd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'surprise': 0, 'fear': 1, 'love': 2, 'sadness': 3, 'anger': 4, 'joy': 5}"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_to_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "a105f18b-76ed-429e-8774-62a79c13e9e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'surprise', 1: 'fear', 2: 'love', 3: 'sadness', 4: 'anger', 5: 'joy'}"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index_to_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "e08ad54e-f771-45d2-8aba-10cf001d7254",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "6ed68334-56e9-47e0-90f6-3cd29214d891",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "tf.keras.layers.Embedding(10000,16,input_length=maxlen),\n",
    "tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(20, return_sequences=True)),\n",
    "tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(20)),\n",
    "tf.keras.layers.Dense(6, activation='softmax')\n",
    "])\n",
    "model.compile(\n",
    "     loss='sparse_categorical_crossentropy',\n",
    "     optimizer='adam',\n",
    "     metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "d56fa80a-235f-4c5f-9a76-0cc4c697f6c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "500/500 [==============================] - 21s 29ms/step - loss: 1.4004 - accuracy: 0.4151 - val_loss: 1.0254 - val_accuracy: 0.5880\n",
      "Epoch 2/20\n",
      "500/500 [==============================] - 13s 26ms/step - loss: 0.6294 - accuracy: 0.7837 - val_loss: 0.4672 - val_accuracy: 0.8495\n",
      "Epoch 3/20\n",
      "500/500 [==============================] - 12s 24ms/step - loss: 0.2887 - accuracy: 0.9032 - val_loss: 0.3978 - val_accuracy: 0.8745\n",
      "Epoch 4/20\n",
      "500/500 [==============================] - 13s 27ms/step - loss: 0.1921 - accuracy: 0.9371 - val_loss: 0.3701 - val_accuracy: 0.8880\n",
      "Epoch 5/20\n",
      "500/500 [==============================] - 13s 27ms/step - loss: 0.1400 - accuracy: 0.9518 - val_loss: 0.4068 - val_accuracy: 0.8795\n",
      "Epoch 6/20\n",
      "500/500 [==============================] - 13s 26ms/step - loss: 0.1137 - accuracy: 0.9616 - val_loss: 0.3850 - val_accuracy: 0.8910\n",
      "Epoch 7/20\n",
      "500/500 [==============================] - 13s 26ms/step - loss: 0.0885 - accuracy: 0.9688 - val_loss: 0.4000 - val_accuracy: 0.8920\n",
      "Epoch 8/20\n",
      "500/500 [==============================] - 13s 26ms/step - loss: 0.0808 - accuracy: 0.9717 - val_loss: 0.3864 - val_accuracy: 0.8905\n",
      "Epoch 9/20\n",
      "500/500 [==============================] - 13s 26ms/step - loss: 0.0705 - accuracy: 0.9764 - val_loss: 0.4053 - val_accuracy: 0.8920\n"
     ]
    }
   ],
   "source": [
    "val_tweets, val_labels = get_tweet(val)\n",
    "val_seq = get_sequences(tokenizer, val_tweets)\n",
    "val_labels= names_to_ids(val_labels)\n",
    "h = model.fit(\n",
    "     padded_train_seq, train_labels,\n",
    "     validation_data=(val_seq, val_labels),\n",
    "     epochs=20,\n",
    "     callbacks=[tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', patience=2)]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "04ad2d33-4173-450c-9baa-c214b79e47bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 1s 8ms/step - loss: 0.3918 - accuracy: 0.8910\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.39179304242134094, 0.890999972820282]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_tweets, test_labels=get_tweet(test)\n",
    "test_seq = get_sequences(tokenizer, test_tweets)\n",
    "test_labels=names_to_ids(test_labels)\n",
    "model.evaluate(test_seq, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "aa6d8b5f-c838-481a-961d-2153266491c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 1s 9ms/step - loss: 0.3918 - accuracy: 0.8910\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.39179304242134094, 0.890999972820282]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(test_seq, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "267ef52c-1ede-49c9-8163-76cf284b1a0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence: i feel like even though things arent quite resolved with my major i have peace about it still\n",
      "Emotion: joy\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "[   2    3   14   75  137   89 1222  157  686   25   11 2181    2   21\n",
      "  849   27   13   72    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0]\n",
      "Predicted Emotion:  joy\n"
     ]
    }
   ],
   "source": [
    "i = random.randint(0,len(test_labels)-1)\n",
    "print('Sentence:', test_tweets[i])\n",
    "print('Emotion:', index_to_class[test_labels[i]])\n",
    "p = model.predict(np.expand_dims(test_seq[i], axis=0))[0]\n",
    "print(test_seq[i])\n",
    "pred_class=index_to_class[np.argmax(p).astype('uint8')]\n",
    "print('Predicted Emotion: ', pred_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "7a27e872-416a-4cdf-90b1-ba5ffcfaeb08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 24ms/step\n",
      "Sentence: i have to fight to be with you!\n",
      "Predicted Emotion:  sadness\n"
     ]
    }
   ],
   "source": [
    "sentence = 'i have to fight to be with you!'\n",
    "sequence = tokenizer.texts_to_sequences([sentence])\n",
    "paddedSequence = pad_sequences(sequence, truncating = 'post', padding='post', maxlen=maxlen)\n",
    "p = model.predict(np.expand_dims(paddedSequence[0], axis=0))[0]\n",
    "pred_class=index_to_class[np.argmax(p).astype('uint8')]\n",
    "print('Sentence:', sentence)\n",
    "print('Predicted Emotion: ', pred_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70f59e04-9a50-4f9c-a013-43ac95f927d7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
